\section{Conclusion}
\label{section:conclusion}

After we have evaluated the performance of the systems on the this Cross-Lingual WSD dataset, we integrate the top-performing system using word embeddings and the trained models into the fork of WordNews. We experimented and implemented with different methods of using word embeddings for supervised WSD. We tried two approaches, by enhancing an existing WSD system, IMS, and by trying a neural network approach. An evaluation of the various methods in WSD system and the existing methods was performed. An initial evaluation was done on existing test data sets from Senseval-2, Senseval-3, SemEval-2007. Adding word embeddings as a feature type to IMS resulted in the system performing competitively or better than the state-of-the-art systems on many of the tasks. This showed that existing supervised approaches can be augmented with word embeddings to give better results. After that, we built a gold-standard English-Chinese Cross-Lingual WSD dataset constructed with sentences from real news articles. This was used as evaluation of the task of translating English words on online news articles. This dataset is made available publicly. Word embeddings improves the performance of the WSD system on the Cross-Lingual WSD dataset. 

As future work, we can look into expanding the existing dictionary with more English words of varying difficulty and including more possible Chinese translations, as we note that there were several instances in the Cross-Lingual WSD dataset where the annotators did not choose an existing translation. An extrinsic evaluation of the Cross-Lingual WSD system should be done with potential users of different language learning application in order to validate that the quality of translations did indeed improve in real world usage. 